{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Playing Connect 4\n",
    "\n",
    "Student Name: [Add your name]\n",
    "\n",
    "I have used the following AI tools: [list tools]\n",
    "\n",
    "I understand that my submission needs to be my own work: [your initials]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "\n",
    "* Implement adversarial search algorithms for strategic game play.\n",
    "* Analyze and optimize search in complex game spaces.\n",
    "* Design effective heuristic evaluation functions.\n",
    "* Compare performance across different agent strategies.\n",
    "* Evaluate algorithmic trade-offs between decision quality and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Total Points: Undergraduates 100, graduate students 110\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed. Submit the completely rendered notebook as a HTML file. \n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You will implement different versions of agents that play Connect 4:\n",
    "\n",
    "> \"Connect 4 is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own discs.\" (see [Connect Four on Wikipedia](https://en.wikipedia.org/wiki/Connect_Four))\n",
    "\n",
    "Note that [Connect-4 has been solved](https://en.wikipedia.org/wiki/Connect_Four#Mathematical_solution)\n",
    "in 1988. A connect-4 solver with a discussion of how to solve different parts of the problem can be found here: https://connect4.gamesolver.org/en/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the Search Problem [10 point]\n",
    "\n",
    "Define the components of the search problem:\n",
    "\n",
    "* Initial state\n",
    "* Actions\n",
    "* Transition model (result function)\n",
    "* Goal state (terminal state and utility)\n",
    "\n",
    "Describe each component and then implement it as a function that can be used by search algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trạng thái ban đầu (bàn cờ trống):\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "------------------------------\n",
      "Các hành động hợp lệ ban đầu: [0, 1, 2, 3, 4, 5, 6]\n",
      "------------------------------\n",
      "Bàn cờ sau khi người chơi 1 thả vào cột 3:\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]]\n",
      "Các hành động hợp lệ bây giờ: [0, 1, 2, 3, 4, 5, 6]\n",
      "------------------------------\n",
      "Tạo một bàn cờ thắng cho người chơi -1:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [-1 -1 -1 -1  0  0  0]]\n",
      "Trò chơi đã kết thúc chưa? -> True\n",
      "Giá trị hữu ích từ góc nhìn của người chơi -1 là: 1\n",
      "Giá trị hữu ích từ góc nhìn của người chơi 1 là: -1\n"
     ]
    }
   ],
   "source": [
    "# Your code/answer goes here.\n",
    "import numpy as np\n",
    "\n",
    "# Các hằng số cho dễ đọc\n",
    "ROWS = 6\n",
    "COLS = 7\n",
    "PLAYER_PIECE = 1\n",
    "AI_PIECE = -1\n",
    "\n",
    "# --- TRIỂN KHAI CÁC THÀNH PHẦN ---\n",
    "\n",
    "def initial_state():\n",
    "    \"\"\"Trả về trạng thái ban đầu: một bàn cờ 6x7 trống.\"\"\"\n",
    "    return np.zeros((ROWS, COLS), dtype=int)\n",
    "\n",
    "def actions(board):\n",
    "    \"\"\"Trả về danh sách các hành động (cột) hợp lệ.\"\"\"\n",
    "    return [col for col in range(COLS) if board[0][col] == 0]\n",
    "\n",
    "def result(board, action, piece):\n",
    "    \"\"\"Trả về bàn cờ mới sau khi người chơi thả quân cờ vào cột `action`.\"\"\"\n",
    "    new_board = board.copy()\n",
    "    for r in range(ROWS - 1, -1, -1):\n",
    "        if new_board[r][action] == 0:\n",
    "            new_board[r][action] = piece\n",
    "            return new_board\n",
    "    return None # Trả về None nếu hành động không hợp lệ\n",
    "\n",
    "def check_win(board, piece):\n",
    "    \"\"\"Kiểm tra xem người chơi có quân cờ `piece` đã thắng hay chưa.\"\"\"\n",
    "    # Kiểm tra hàng ngang\n",
    "    for c in range(COLS - 3):\n",
    "        for r in range(ROWS):\n",
    "            if np.all(board[r, c:c+4] == piece):\n",
    "                return True\n",
    "    # Kiểm tra hàng dọc\n",
    "    for c in range(COLS):\n",
    "        for r in range(ROWS - 3):\n",
    "            if np.all(board[r:r+4, c] == piece):\n",
    "                return True\n",
    "    # Kiểm tra đường chéo dương (\\)\n",
    "    for c in range(COLS - 3):\n",
    "        for r in range(ROWS - 3):\n",
    "            if all(board[r+i, c+i] == piece for i in range(4)):\n",
    "                return True\n",
    "    # Kiểm tra đường chéo âm (/)\n",
    "    for c in range(COLS - 3):\n",
    "        for r in range(3, ROWS):\n",
    "            if all(board[r-i, c+i] == piece for i in range(4)):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def is_terminal(board):\n",
    "    \"\"\"Kiểm tra xem trò chơi đã kết thúc hay chưa.\"\"\"\n",
    "    return check_win(board, PLAYER_PIECE) or check_win(board, AI_PIECE) or len(actions(board)) == 0\n",
    "\n",
    "def utility(board, piece):\n",
    "    \"\"\"Trả về giá trị hữu ích (+1, -1, 0) cho một trạng thái kết thúc.\"\"\"\n",
    "    opponent_piece = AI_PIECE if piece == PLAYER_PIECE else PLAYER_PIECE\n",
    "    if check_win(board, piece):\n",
    "        return 1\n",
    "    elif check_win(board, opponent_piece):\n",
    "        return -1\n",
    "    else: # Hòa\n",
    "        return 0\n",
    "\n",
    "# --- KIỂM TRA (TEST) CÁC HÀM ---\n",
    "# Tạo một bàn cờ trống để bắt đầu\n",
    "test_board = initial_state()\n",
    "print(\"Trạng thái ban đầu (bàn cờ trống):\")\n",
    "print(test_board)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Kiểm tra các hành động hợp lệ\n",
    "print(f\"Các hành động hợp lệ ban đầu: {actions(test_board)}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Thực hiện một nước đi\n",
    "test_board = result(test_board, 3, PLAYER_PIECE)\n",
    "print(\"Bàn cờ sau khi người chơi 1 thả vào cột 3:\")\n",
    "print(test_board)\n",
    "print(f\"Các hành động hợp lệ bây giờ: {actions(test_board)}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Tạo một bàn cờ thắng để kiểm tra\n",
    "win_board = initial_state()\n",
    "for i in range(4):\n",
    "    win_board = result(win_board, i, AI_PIECE)\n",
    "print(\"Tạo một bàn cờ thắng cho người chơi -1:\")\n",
    "print(win_board)\n",
    "print(f\"Trò chơi đã kết thúc chưa? -> {is_terminal(win_board)}\")\n",
    "print(f\"Giá trị hữu ích từ góc nhìn của người chơi -1 là: {utility(win_board, AI_PIECE)}\")\n",
    "print(f\"Giá trị hữu ích từ góc nhìn của người chơi 1 là: {utility(win_board, PLAYER_PIECE)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mô tả các thành phần của bài toán tìm kiếm\n",
    "\n",
    "* **Trạng thái ban đầu (Initial State):** Là một bàn cờ trống, được biểu diễn bằng một ma trận NumPy kích thước 6x7 chứa toàn bộ giá trị là 0.\n",
    "\n",
    "* **Hành động (Actions):** Tại mỗi trạng thái, các hành động hợp lệ là một danh sách các chỉ số cột (từ 0 đến 6) mà người chơi có thể thả quân cờ vào. Một cột được coi là hợp lệ nếu ô trên cùng của nó vẫn còn trống (giá trị là 0).\n",
    "\n",
    "* **Mô hình chuyển tiếp (Transition Model - `result`):** Hàm này nhận vào trạng thái bàn cờ hiện tại, một hành động (cột đã chọn) và quân cờ của người chơi (1 hoặc -1). Nó trả về một trạng thái bàn cờ mới sau khi quân cờ đã được đặt vào vị trí trống thấp nhất của cột đó.\n",
    "\n",
    "* **Trạng thái kết thúc và Hàm hữu ích (Goal State - `terminal` & `utility`):**\n",
    "    * **Trạng thái kết thúc (`is_terminal`):** Trò chơi được xem là kết thúc khi một trong các điều kiện sau được thỏa mãn:\n",
    "        * Một người chơi tạo được một hàng có 4 quân cờ liên tiếp (theo chiều ngang, dọc, hoặc chéo).\n",
    "        * Tất cả các ô trên bàn cờ đã được lấp đầy, dẫn đến kết quả hòa.\n",
    "    * **Hàm hữu ích (`utility`):** Được tính tại một trạng thái kết thúc từ góc nhìn của một người chơi cụ thể:\n",
    "        * **+1:** Nếu người chơi đó thắng.\n",
    "        * **-1:** Nếu đối thủ của họ thắng.\n",
    "        * **0:** Nếu ván cờ hòa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the state space? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ước tính cận trên cho không gian trạng thái là 3^42 ≈ 1.094190e+20\n"
     ]
    }
   ],
   "source": [
    "# Your answer goes here.\n",
    "# Ước tính kích thước không gian trạng thái\n",
    "\n",
    "# Bàn cờ Connect 4 có 6 hàng và 7 cột, tổng cộng 42 ô.\n",
    "# Mỗi ô có thể ở một trong 3 trạng thái: trống (0), người chơi 1 (1), hoặc người chơi -1 (-1).\n",
    "\n",
    "# Do đó, một ước tính cận trên (upper bound) đơn giản cho số lượng trạng thái là 3 lũy thừa 42.\n",
    "upper_bound = 3**42\n",
    "\n",
    "print(f\"Ước tính cận trên cho không gian trạng thái là 3^42 ≈ {upper_bound:e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Giải thích:**\n",
    "* Bàn cờ có **42 ô** (6 hàng x 7 cột).\n",
    "* Mỗi ô có thể ở một trong **3 trạng thái**: trống (0), người chơi 1 (1), hoặc người chơi 2 (-1).\n",
    "* Do đó, số lượng cấu hình bàn cờ tối đa có thể có là $3 \\times 3 \\times \\dots \\times 3$ (42 lần), tức là $3^{42}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the game tree that minimax search will go through? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ước tính cận trên cho kích thước cây trò chơi là 7^42 ≈ 3.119735e+35\n"
     ]
    }
   ],
   "source": [
    "# Your answer goes here.\n",
    "# Ước tính kích thước cây trò chơi\n",
    "\n",
    "# Cây trò chơi biểu diễn tất cả các chuỗi nước đi có thể xảy ra.\n",
    "# Hệ số nhánh (branching factor) `b` là số lựa chọn ở mỗi lượt, tối đa là 7 (cho 7 cột).\n",
    "# Độ sâu (depth) `d` của cây là số nước đi tối đa trong một ván, là 42 (6x7).\n",
    "\n",
    "# Một ước tính cận trên cho kích thước cây trò chơi là b^d.\n",
    "branching_factor = 7\n",
    "depth = 42\n",
    "tree_size_upper_bound = branching_factor**depth\n",
    "\n",
    "print(f\"Ước tính cận trên cho kích thước cây trò chơi là {branching_factor}^{depth} ≈ {tree_size_upper_bound:e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Giải thích:**\n",
    "* **Hệ số nhánh (`b`):** Tại mỗi lượt, một người chơi có tối đa **7 lựa chọn** (7 cột để thả quân cờ).\n",
    "* **Độ sâu (`d`):** Một ván cờ có tối đa **42 lượt đi** (tương ứng với 42 ô trên bàn cờ).\n",
    "* Do đó, tổng số nút lá trong cây trò chơi có thể được ước tính bằng $b^d = 7^{42}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Game Environment and Random Agent [25 point]\n",
    "\n",
    "Use a numpy character array as the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def empty_board(shape=(6, 7)):\n",
    "    return np.full(shape=shape, fill_value=0)\n",
    "\n",
    "print(empty_board())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard board is $6 \\times 7$ but you can use smaller boards to test your code. Instead of colors (red and yellow), I use 1 and -1 to represent the players. Make sure that your agent functions all have the from: `agent_type(board, player = 1)`, where board is the current board position (in the format above) and player is the player whose next move it is and who the agent should play (as 1 and -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization code by Randolph Rankin\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize(board):\n",
    "    plt.axes()\n",
    "    rectangle=plt.Rectangle((-0.5,len(board)*-1+0.5),len(board[0]),len(board),fc='blue')\n",
    "    circles=[]\n",
    "    for i,row in enumerate(board):\n",
    "        for j,val in enumerate(row):\n",
    "            color='white' if val==0 else 'red' if val==1 else 'yellow'\n",
    "            circles.append(plt.Circle((j,i*-1),0.4,fc=color))\n",
    "\n",
    "    plt.gca().add_patch(rectangle)\n",
    "    for circle in circles:\n",
    "        plt.gca().add_patch(circle)\n",
    "\n",
    "    plt.axis('scaled')\n",
    "    plt.show()\n",
    "    \n",
    "board = [[0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 0, 0, 0],\n",
    "         [0,-1,-1, 1,-1, 0, 0]]\n",
    "visualize(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Implement helper functions for:\n",
    "\n",
    "* A check for available actions in each state `actions(state)`.\n",
    "* The transition model `result(state, player, action)`.\n",
    "* Check for terminal states `terminal(state)`.\n",
    "* The utility function `utility(state, player)`.\n",
    "\n",
    "The player argument is used so your agent can play red or yellow.\n",
    "Make sure that all these functions work with boards of different sizes (number of columns and rows).\n",
    "You can follow the [tic-tac-toe example from class.](https://colab.research.google.com/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_definitions.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bắt đầu Test các Hàm Helper ---\n",
      "1. Test `actions`: Các cột hợp lệ trên bàn cờ trống -> [0, 1, 2, 3, 4, 5, 6]\n",
      "\n",
      "2. Test `result`: Bàn cờ sau khi người chơi 1 đi vào cột 3:\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0]]\n",
      "\n",
      "3. Test `terminal` và `utility` trên bàn cờ thắng:\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [1 1 1 1 0 0 0]]\n",
      "   - terminal(win_board) -> True\n",
      "   - utility(win_board, PLAYER_PIECE) -> 1\n",
      "   - utility(win_board, AI_PIECE) -> -1\n",
      "\n",
      "--- Kết thúc Test ---\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# Your code/ answer goes here.\n",
    "import numpy as np\n",
    "\n",
    "# Các hằng số cho dễ đọc\n",
    "ROWS = 6\n",
    "COLS = 7\n",
    "PLAYER_PIECE = 1\n",
    "AI_PIECE = -1\n",
    "\n",
    "# 1. Hàm actions(board)\n",
    "def actions(board):\n",
    "    \"\"\"Trả về danh sách các cột hợp lệ (chưa đầy).\"\"\"\n",
    "    return [col for col in range(board.shape[1]) if board[0][col] == 0]\n",
    "\n",
    "# 2. Hàm result(board, player, action)\n",
    "def result(board, player, action):\n",
    "    \"\"\"Thực hiện một nước đi và trả về bàn cờ mới.\"\"\"\n",
    "    new_board = board.copy()\n",
    "    for r in range(board.shape[0] - 1, -1, -1):\n",
    "        if new_board[r][action] == 0:\n",
    "            new_board[r][action] = player\n",
    "            return new_board\n",
    "    return None # Hành động không hợp lệ\n",
    "\n",
    "# Helper function để kiểm tra thắng\n",
    "def check_win(board, piece):\n",
    "    \"\"\"Kiểm tra xem người chơi có quân cờ 'piece' đã thắng hay chưa.\"\"\"\n",
    "    rows, cols = board.shape\n",
    "    # Ngang\n",
    "    for c in range(cols - 3):\n",
    "        for r in range(rows):\n",
    "            if all(board[r, c+i] == piece for i in range(4)):\n",
    "                return True\n",
    "    # Dọc\n",
    "    for c in range(cols):\n",
    "        for r in range(rows - 3):\n",
    "            if all(board[r+i, c] == piece for i in range(4)):\n",
    "                return True\n",
    "    # Chéo dương (\\)\n",
    "    for c in range(cols - 3):\n",
    "        for r in range(rows - 3):\n",
    "            if all(board[r+i, c+i] == piece for i in range(4)):\n",
    "                return True\n",
    "    # Chéo âm (/)\n",
    "    for c in range(cols - 3):\n",
    "        for r in range(3, rows):\n",
    "            if all(board[r-i, c+i] == piece for i in range(4)):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# 3. Hàm terminal(board)\n",
    "def terminal(board):\n",
    "    \"\"\"Kiểm tra xem trò chơi đã ở trạng thái kết thúc hay chưa.\"\"\"\n",
    "    return check_win(board, PLAYER_PIECE) or check_win(board, AI_PIECE) or len(actions(board)) == 0\n",
    "\n",
    "# 4. Hàm utility(board, player)\n",
    "def utility(board, player):\n",
    "    \"\"\"Trả về giá trị hữu ích cho một trạng thái kết thúc.\"\"\"\n",
    "    opponent = AI_PIECE if player == PLAYER_PIECE else PLAYER_PIECE\n",
    "    if check_win(board, player):\n",
    "        return 1\n",
    "    elif check_win(board, opponent):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# --- PHẦN KIỂM TRA (TEST) ---\n",
    "print(\"--- Bắt đầu Test các Hàm Helper ---\")\n",
    "board = np.zeros((ROWS, COLS), dtype=int)\n",
    "\n",
    "# Test actions()\n",
    "print(f\"1. Test `actions`: Các cột hợp lệ trên bàn cờ trống -> {actions(board)}\")\n",
    "\n",
    "# Test result()\n",
    "board_after_move = result(board, 3, PLAYER_PIECE)\n",
    "print(\"\\n2. Test `result`: Bàn cờ sau khi người chơi 1 đi vào cột 3:\")\n",
    "print(board_after_move)\n",
    "\n",
    "# Test terminal() and utility()\n",
    "win_board = board.copy()\n",
    "win_board[5][0] = PLAYER_PIECE\n",
    "win_board[5][1] = PLAYER_PIECE\n",
    "win_board[5][2] = PLAYER_PIECE\n",
    "win_board[5][3] = PLAYER_PIECE\n",
    "print(\"\\n3. Test `terminal` và `utility` trên bàn cờ thắng:\")\n",
    "print(win_board)\n",
    "print(f\"   - terminal(win_board) -> {terminal(win_board)}\")\n",
    "print(f\"   - utility(win_board, PLAYER_PIECE) -> {utility(win_board, PLAYER_PIECE)}\")\n",
    "print(f\"   - utility(win_board, AI_PIECE) -> {utility(win_board, AI_PIECE)}\")\n",
    "\n",
    "print(\"\\n--- Kết thúc Test ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giải thích \n",
    "\n",
    "* **`actions(board)`:** Hàm này nhận vào một bàn cờ và trả về một danh sách các cột mà người chơi có thể thả quân cờ vào. Nó hoạt động bằng cách kiểm tra hàng trên cùng (hàng 0) của mỗi cột. Nếu một ô ở hàng này vẫn còn trống (giá trị 0), cột đó được coi là một hành động hợp lệ.\n",
    "\n",
    "* **`result(board, player, action)`:** Đây là hàm chuyển tiếp trạng thái. Nó tạo một bản sao của bàn cờ hiện tại để tránh thay đổi trạng thái gốc. Sau đó, nó tìm hàng trống thấp nhất trong cột `action` và đặt quân cờ của `player` vào đó, rồi trả về bàn cờ mới.\n",
    "\n",
    "* **`terminal(board)`:** Hàm này kiểm tra xem trò chơi đã kết thúc hay chưa. Nó trả về `True` nếu một trong ba điều kiện được thỏa mãn: (1) người chơi 1 (`PLAYER_PIECE`) thắng, (2) người chơi -1 (`AI_PIECE`) thắng, hoặc (3) không còn hành động hợp lệ nào (bàn cờ đã đầy, dẫn đến hòa).\n",
    "\n",
    "* **`utility(board, player)`:** Hàm này chỉ được gọi khi trò chơi đã ở trạng thái kết thúc (`terminal` trả về `True`). Nó tính toán giá trị của ván cờ từ góc nhìn của người chơi `player` được truyền vào: trả về **1** nếu họ thắng, **-1** nếu đối thủ của họ thắng, và **0** nếu hòa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
    "\n",
    "`def random_player(board, player = 1): ...`\n",
    "\n",
    "The argument `player` is used for agents that do not store what color they are playing. The value passed on by the environment should be 1 ot -1 for player red and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bắt đầu Test Tác nhân Ngẫu nhiên ---\n",
      "Bàn cờ thử nghiệm:\n",
      "[[ 1 -1  0 -1  1 -1  1]\n",
      " [-1  1  1  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1 -1  1]\n",
      " [-1  1 -1  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1 -1  1]\n",
      " [-1  1 -1  1 -1  1 -1]]\n",
      "Các nước đi hợp lệ: [2]\n",
      "Tác nhân ngẫu nhiên đã chọn cột: 2\n",
      "Nước đi được chọn có nằm trong danh sách hợp lệ không? -> True\n",
      "\n",
      "--- Kết thúc Test ---\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# Your code/ answer goes here.\n",
    "import random\n",
    "\n",
    "def random_player(board, player = 1):\n",
    "    \"\"\"\n",
    "    Tác nhân này nhận vào bàn cờ hiện tại và người chơi hiện tại,\n",
    "    sau đó trả về một hành động hợp lệ được chọn ngẫu nhiên.\n",
    "    \"\"\"\n",
    "    valid_actions = actions(board)\n",
    "    if not valid_actions:\n",
    "        return None # Không còn nước đi nào\n",
    "    return random.choice(valid_actions)\n",
    "\n",
    "# --- PHẦN KIỂM TRA (TEST) ---\n",
    "print(\"--- Bắt đầu Test Tác nhân Ngẫu nhiên ---\")\n",
    "# Tạo một bàn cờ gần đầy\n",
    "test_board_rand = np.array([\n",
    "    [ 1, -1, 0, -1,  1, -1,  1],\n",
    "    [-1,  1, 1,  1, -1,  1, -1],\n",
    "    [ 1, -1, 1, -1,  1, -1,  1],\n",
    "    [-1,  1,-1,  1, -1,  1, -1],\n",
    "    [ 1, -1, 1, -1,  1, -1,  1],\n",
    "    [-1,  1,-1,  1, -1,  1, -1]\n",
    "], dtype=int)\n",
    "\n",
    "print(\"Bàn cờ thử nghiệm:\")\n",
    "print(test_board_rand)\n",
    "valid_moves = actions(test_board_rand)\n",
    "print(f\"Các nước đi hợp lệ: {valid_moves}\")\n",
    "\n",
    "# Chạy tác nhân ngẫu nhiên\n",
    "chosen_action = random_player(test_board_rand, 1)\n",
    "print(f\"Tác nhân ngẫu nhiên đã chọn cột: {chosen_action}\")\n",
    "print(f\"Nước đi được chọn có nằm trong danh sách hợp lệ không? -> {chosen_action in valid_moves}\")\n",
    "print(\"\\n--- Kết thúc Test ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giải thích \n",
    "\n",
    "Hàm `random_player(board, player)` là một tác nhân chơi game đơn giản.\n",
    "1.  Nó gọi hàm `actions(board)` để lấy danh sách tất cả các cột hợp lệ có thể đi.\n",
    "2.  Sau đó, nó sử dụng thư viện `random` của Python để chọn một phần tử ngẫu nhiên từ danh sách này.\n",
    "3.  Cuối cùng, nó trả về chỉ số của cột đã được chọn làm nước đi tiếp theo.\n",
    "\n",
    "Tác nhân này không có bất kỳ chiến lược nào và chỉ đơn thuần thực hiện các nước đi hợp lệ một cách ngẫu nhiên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
    "\n",
    "How often does each player win? Is the result expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu thực nghiệm: 1000 ván giữa hai người chơi ngẫu nhiên...\n",
      "\n",
      "Thực nghiệm hoàn thành sau 3.38 giây.\n",
      "\n",
      "--- Kết quả Thống kê ---\n",
      "Người chơi 1 (đi trước) thắng: 584 ván (58.4%)\n",
      "Người chơi 2 (đi sau) thắng:  413 ván (41.3%)\n",
      "Số ván hòa:                   3 ván (0.3%)\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here..\n",
    "import time\n",
    "def play_game(player1_agent, player2_agent, rows=6, cols=7):\n",
    "    \"\"\"Hàm mô phỏng một ván cờ hoàn chỉnh giữa hai tác nhân.\"\"\"\n",
    "    board = np.zeros((rows, cols), dtype=int)\n",
    "    current_player_piece = 1\n",
    "    \n",
    "    while not terminal(board):\n",
    "        agent = player1_agent if current_player_piece == 1 else player2_agent\n",
    "        action = agent(board, current_player_piece)\n",
    "        \n",
    "        if action is None or action not in actions(board):\n",
    "            return -current_player_piece \n",
    "        \n",
    "        board = result(board, current_player_piece, action)\n",
    "        current_player_piece *= -1\n",
    "        \n",
    "    if check_win(board, 1):\n",
    "        return 1\n",
    "    elif check_win(board, -1):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# --- THỰC NGHIỆM: 2 TÁC NHÂN NGẪU NHIÊN ĐẤU 1000 VÁN ---\n",
    "# Giả định các hàm play_game, random_player, PLAYER_PIECE, AI_PIECE đã được định nghĩa ở các cell trước.\n",
    "\n",
    "print(\"Bắt đầu thực nghiệm: 1000 ván giữa hai người chơi ngẫu nhiên...\")\n",
    "num_games = 1000\n",
    "results = {PLAYER_PIECE: 0, AI_PIECE: 0, 0: 0} # Sử dụng hằng số đã định nghĩa\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(num_games):\n",
    "    winner = play_game(random_player, random_player)\n",
    "    results[winner] += 1\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nThực nghiệm hoàn thành sau {end_time - start_time:.2f} giây.\")\n",
    "print(\"\\n--- Kết quả Thống kê ---\")\n",
    "p1_wins = results[PLAYER_PIECE]\n",
    "p2_wins = results[AI_PIECE]\n",
    "draws = results[0]\n",
    "\n",
    "print(f\"Người chơi 1 (đi trước) thắng: {p1_wins} ván ({p1_wins/num_games:.1%})\")\n",
    "print(f\"Người chơi 2 (đi sau) thắng:  {p2_wins} ván ({p2_wins/num_games:.1%})\")\n",
    "print(f\"Số ván hòa:                   {draws} ván ({draws/num_games:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân tích Kết quả Thực nghiệm\n",
    "\n",
    "**Tần suất thắng của mỗi người chơi:**\n",
    "* **Người chơi 1 (đi trước):** Thường thắng khoảng **55% - 60%** số ván.\n",
    "* **Người chơi 2 (đi sau):** Thường thắng khoảng **40% - 45%** số ván.\n",
    "* **Hòa:** Tỷ lệ hòa trong các ván đấu ngẫu nhiên thường rất thấp, gần như không đáng kể.\n",
    "\n",
    "**Kết quả này có như mong đợi không?**\n",
    "* **Có, kết quả này là hoàn toàn dự kiến được.** Trong trò chơi Connect 4, người đi trước có một lợi thế chiến lược nhỏ. Việc được đi nước đầu tiên cho phép người chơi 1 có cơ hội đầu tiên để chiếm các vị trí quan trọng (đặc biệt là cột giữa) và thiết lập các mối đe dọa.\n",
    "* Ngay cả khi cả hai người chơi đều thực hiện các nước đi một cách hoàn toàn ngẫu nhiên, lợi thế vốn có này vẫn được thể hiện qua một tỷ lệ thắng cao hơn sau khi thực hiện một số lượng lớn các ván đấu. Do đó, việc Người chơi 1 thắng nhiều hơn Người chơi 2 là một kết quả hợp lý."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Minimax Search with Alpha-Beta Pruning\n",
    "\n",
    "### Implement the Search [20 points] \n",
    "\n",
    "Implement minimax search starting from a given board for specifying the player.\n",
    "\n",
    "__Important Notes:__ \n",
    "* You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
    "* Make sure that all your agent functions have a signature consistent with the random agent above and that it [uses a class to store state information.](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/HOWTOs/store_agent_state_information.ipynb)\n",
    "This is essential to be able play against agents from other students later.\n",
    "* The game tree for a $6 \\times 7$ board is huge and optimal algorithms need to visit each or a large percentage of all nodes in the tree. You can experiment with smaller boards like a $4 \\times 4$ board first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here.\n",
    "# --- TRIỂN KHAI MINIMAX VỚI ALPHA-BETA --\n",
    "import math\n",
    "\n",
    "def minimax(board, depth, alpha, beta, maximizing_player, player_piece):\n",
    "    \"\"\"Hàm đệ quy Minimax với cắt tỉa Alpha-Beta.\"\"\"\n",
    "    is_terminal_node = terminal(board)\n",
    "    if depth == 0 or is_terminal_node:\n",
    "        if is_terminal_node:\n",
    "            return utility(board, player_piece), None\n",
    "        else:\n",
    "            # Khi hết độ sâu, trả về 0 vì chưa có heuristic\n",
    "            return 0, None\n",
    "\n",
    "    valid_actions = actions(board)\n",
    "    best_action = random.choice(valid_actions) # Chọn một nước đi ngẫu nhiên để không bao giờ bị lỗi\n",
    "\n",
    "    if maximizing_player:\n",
    "        value = -math.inf\n",
    "        for action in valid_actions:\n",
    "            new_board = result(board, player_piece, action)\n",
    "            new_score, _ = minimax(new_board, depth - 1, alpha, beta, False, player_piece)\n",
    "            if new_score > value:\n",
    "                value = new_score\n",
    "                best_action = action\n",
    "            alpha = max(alpha, value)\n",
    "            if alpha >= beta:\n",
    "                break # Cắt tỉa Beta\n",
    "        return value, best_action\n",
    "    else: # Minimizing player (đối thủ)\n",
    "        value = math.inf\n",
    "        opponent_piece = AI_PIECE if player_piece == PLAYER_PIECE else PLAYER_PIECE\n",
    "        for action in valid_actions:\n",
    "            new_board = result(board, opponent_piece, action)\n",
    "            new_score, _ = minimax(new_board, depth - 1, alpha, beta, True, player_piece)\n",
    "            if new_score < value:\n",
    "                value = new_score\n",
    "                best_action = action\n",
    "            beta = min(beta, value)\n",
    "            if alpha >= beta:\n",
    "                break # Cắt tỉa Alpha\n",
    "        return value, best_action\n",
    "\n",
    "def minimax_alpha_beta_player(board, player = 1):\n",
    "    \"\"\"Tác nhân agent sử dụng Minimax với Alpha-Beta.\"\"\"\n",
    "    # Độ sâu tìm kiếm - giá trị này rất quan trọng\n",
    "    # Đối với bàn cờ nhỏ, 4 hoặc 5 là hợp lý\n",
    "    SEARCH_DEPTH = 4\n",
    "    _, action = minimax(board, SEARCH_DEPTH, -math.inf, math.inf, True, player)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giải thích Thuật toán Minimax với Cắt tỉa Alpha-Beta\n",
    "\n",
    "Hàm `minimax` được triển khai theo phương pháp đệ quy để duyệt cây trò chơi:\n",
    "* **Điều kiện dừng:** Đệ quy sẽ dừng khi đạt đến độ sâu tìm kiếm tối đa (`depth == 0`) hoặc khi gặp một trạng thái kết thúc (`is_terminal_node`). Tại đây, nó sẽ trả về giá trị hữu ích của trạng thái đó.\n",
    "* **`maximizing_player`:** Một biến boolean để xác định lượt đi hiện tại là của người chơi cần tối đa hóa điểm số (`True`) hay của đối thủ cần tối thiểu hóa điểm số (`False`).\n",
    "* **Cắt tỉa Alpha-Beta:**\n",
    "    * **`alpha`**: Lưu trữ giá trị tốt nhất (cao nhất) mà người chơi MAX có thể đảm bảo trên đường đi hiện tại.\n",
    "    * **`beta`**: Lưu trữ giá trị tốt nhất (thấp nhất) mà người chơi MIN có thể đảm bảo.\n",
    "    * Thuật toán sẽ \"cắt tỉa\" (bỏ qua) việc duyệt các nhánh con khi `alpha >= beta`, vì những nhánh đó chắc chắn sẽ không dẫn đến một kết quả tốt hơn những lựa chọn đã có.\n",
    "* **`minimax_alpha_beta_player`:** Đây là hàm agent chính, nó đóng vai trò là giao diện để gọi thuật toán `minimax` với độ sâu tìm kiếm (`SEARCH_DEPTH`) và các giá trị `alpha`, `beta` ban đầu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with some manually created boards (at least 5) to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bắt đầu Test Tác nhân Minimax trên các bàn cờ thủ công ---\n",
      "\n",
      "Test 1: Người chơi 1 (đỏ) có thể thắng ngay tại cột 3.\n",
      " -> Tác nhân chọn cột: 3\n",
      "\n",
      "Test 2: Người chơi 1 (đỏ) phải chặn người chơi -1 (vàng) tại cột 3.\n",
      " -> Tác nhân chọn cột: 3\n",
      "\n",
      "Test 3: Người chơi 1 có thể thắng ngay tại cột 3.\n",
      " -> Tác nhân chọn cột: 3\n",
      "\n",
      "Test 4: Người chơi 1 nên đi vào cột 3 để tạo bẫy thắng kép.\n",
      " -> Tác nhân chọn cột: 3\n",
      "\n",
      "Test 5: Người chơi 1 phải chặn mối đe dọa thắng ở cột 2.\n",
      " -> Tác nhân chọn cột: 2\n",
      "\n",
      "--- Tất cả các bài test thủ công đều thành công! ---\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "print(\"--- Bắt đầu Test Tác nhân Minimax trên các bàn cờ thủ công ---\")\n",
    "\n",
    "# (Các hàm minimax và agent giữ nguyên như trước)\n",
    "# Bạn có thể giữ nguyên SEARCH_DEPTH = 4 hoặc 5, vì nước đi này là bắt buộc và sẽ được tìm thấy ở độ sâu thấp.\n",
    "def minimax_alpha_beta_player(board, player = 1):\n",
    "    SEARCH_DEPTH = 5 \n",
    "    _, action = minimax(board, SEARCH_DEPTH, -math.inf, math.inf, True, player)\n",
    "    return action\n",
    "\n",
    "# Test 1, 2, 3, 4 giữ nguyên vì chúng đã đúng\n",
    "# ... (code test 1, 2, 3, 4) ...\n",
    "# Test 1: Cơ hội thắng ngay lập tức cho người chơi 1\n",
    "board1 = np.zeros((6,7), dtype=int)\n",
    "board1[5] = [1, 1, 1, 0, 0, -1, -1]\n",
    "print(\"\\nTest 1: Người chơi 1 (đỏ) có thể thắng ngay tại cột 3.\")\n",
    "action1 = minimax_alpha_beta_player(board1, 1)\n",
    "print(f\" -> Tác nhân chọn cột: {action1}\")\n",
    "assert action1 == 3\n",
    "\n",
    "# Test 2: Phải chặn đối thủ (-1) thắng\n",
    "board2 = np.zeros((6,7), dtype=int)\n",
    "board2[5] = [-1, -1, -1, 0, 1, 1, 0]\n",
    "print(\"\\nTest 2: Người chơi 1 (đỏ) phải chặn người chơi -1 (vàng) tại cột 3.\")\n",
    "action2 = minimax_alpha_beta_player(board2, 1)\n",
    "print(f\" -> Tác nhân chọn cột: {action2}\")\n",
    "assert action2 == 3\n",
    "\n",
    "# Test 3: Chọn nước đi TỐI ƯU (là nước đi chiến thắng)\n",
    "board3 = np.array([\n",
    "    [ 0,  0,  0,  0,  0,  0,  0],\n",
    "    [ 0,  0,  0,  0,  0,  0,  0],\n",
    "    [ 0,  0,  0,  0,  0,  0,  0],\n",
    "    [ 0, -1, -1,  0,  0,  0,  0],\n",
    "    [ 1,  1,  1,  0, -1,  0,  0],\n",
    "    [-1, -1,  1,  1,  0,  0,  0]], dtype=int)\n",
    "print(\"\\nTest 3: Người chơi 1 có thể thắng ngay tại cột 3.\")\n",
    "action3 = minimax_alpha_beta_player(board3, 1)\n",
    "print(f\" -> Tác nhân chọn cột: {action3}\")\n",
    "assert action3 == 3\n",
    "\n",
    "# Test 4: Tạo một bẫy thắng\n",
    "board4 = np.array([\n",
    "    [ 0,  0,  0,  0,  0,  0,  0],\n",
    "    [ 0,  0,  0,  0,  0,  0,  0],\n",
    "    [ 0,  0,  0,  0,  0,  0,  0],\n",
    "    [ 0,  0,  0,  0,  0,  0,  0],\n",
    "    [ 0, -1, -1,  0,  0,  0,  0],\n",
    "    [ 0,  1,  1,  0,  1,  0,  0]], dtype=int)\n",
    "print(\"\\nTest 4: Người chơi 1 nên đi vào cột 3 để tạo bẫy thắng kép.\")\n",
    "action4 = minimax_alpha_beta_player(board4, 1)\n",
    "print(f\" -> Tác nhân chọn cột: {action4}\")\n",
    "assert action4 == 3\n",
    "\n",
    "# Test 5: Tình huống phòng thủ bắt buộc\n",
    "board5 = np.array([\n",
    "    [ 0,  0,  0,  0,  0,  0,  0],\n",
    "    [ 0,  0,  0,  0,  0,  0,  0],\n",
    "    [ 0,  0,  0,  0,  0,  0,  0],\n",
    "    [ 0,  0, -1,  1,  0,  0,  0],\n",
    "    [ 0,  1, -1, -1,  0,  0,  0],\n",
    "    [ 1,  1, -1,  1,  0,  0,  0]], dtype=int)\n",
    "print(\"\\nTest 5: Người chơi 1 phải chặn mối đe dọa thắng ở cột 2.\")\n",
    "action5 = minimax_alpha_beta_player(board5, 1)\n",
    "print(f\" -> Tác nhân chọn cột: {action5}\")\n",
    "# SỬA LỖI: Sửa assert thành 2, vì đây là nước đi phòng thủ bắt buộc.\n",
    "assert action5 == 2\n",
    "\n",
    "print(\"\\n--- Tất cả các bài test thủ công đều thành công! ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân tích các Bài kiểm tra Thủ công\n",
    "\n",
    "Các bài kiểm tra trên được thiết kế để xác minh rằng tác nhân Minimax có thể đưa ra các quyết định chiến thuật hợp lý:\n",
    "\n",
    "1.  **Test 1 (Tấn công):** Tác nhân đã nhận ra cơ hội thắng ngay lập tức và chọn đúng cột để tạo thành một hàng 4 quân.\n",
    "\n",
    "2.  **Test 2 (Phòng thủ):** Tác nhân xác định chính xác mối đe dọa từ đối thủ (sắp tạo hàng 4 quân) và thực hiện nước đi chặn cần thiết.\n",
    "\n",
    "3.  **Test 3 (Tấn công Tối ưu):** Trong tình huống này, tác nhân đã xác định đúng nước đi ở **cột 3** là nước đi chiến thắng ngay lập tức, ưu tiên nó hơn các nước đi phòng thủ khác.\n",
    "\n",
    "4.  **Test 4 (Tạo bẫy):** Tác nhân đã chọn một nước đi tạo ra hai mối đe dọa thắng cùng lúc, khiến đối thủ không thể chặn cả hai và đảm bảo chiến thắng ở lượt tiếp theo.\n",
    "\n",
    "5.  **Test 5 (Phòng thủ Bắt buộc):** Trong một tình huống phức tạp, tác nhân đã tính toán và tìm ra nước đi **duy nhất** ở **cột 2** để ngăn chặn một trận thua sắp xảy ra ngay lập tức. Đây là minh chứng cho thấy thuật toán hoạt động chính xác khi ưu tiên tránh thất bại."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns/rows. Explain why using this algorithm on a standard $6 \\times 7$ board is not feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phân tích thời gian thực thi theo kích thước bàn cờ ---\n",
      "Thời gian để quyết định một nước đi trên bàn cờ 4x4: 0.0000 giây\n",
      "Thời gian để quyết định một nước đi trên bàn cờ 4x5: 0.0074 giây\n",
      "Thời gian để quyết định một nước đi trên bàn cờ 5x5: 0.0076 giây\n",
      "Thời gian để quyết định một nước đi trên bàn cờ 5x6: 0.0130 giây\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# Your code/ answer goes here.\n",
    "print(\"--- Phân tích thời gian thực thi theo kích thước bàn cờ ---\")\n",
    "\n",
    "def time_analysis_player(board, player=1):\n",
    "    \"\"\"Một phiên bản của agent để đo thời gian với độ sâu cố định.\"\"\"\n",
    "    # Độ sâu tìm kiếm càng lớn, thời gian tăng theo cấp số nhân.\n",
    "    # Chọn độ sâu 4 để có thể so sánh.\n",
    "    SEARCH_DEPTH = 4\n",
    "    start_time = time.time()\n",
    "    minimax(board, SEARCH_DEPTH, -math.inf, math.inf, True, player)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "board_sizes = [(4, 4), (4, 5), (5, 5), (5, 6)]\n",
    "\n",
    "for rows, cols in board_sizes:\n",
    "    # Tạo bàn cờ trống với kích thước tương ứng\n",
    "    board = np.zeros((rows, cols), dtype=int)\n",
    "    \n",
    "    # Đặt một vài quân cờ để mô phỏng giữa ván đấu (khó hơn bàn cờ trống)\n",
    "    if rows > 2 and cols > 2:\n",
    "        board[rows-1][cols//2] = PLAYER_PIECE\n",
    "        board[rows-1][cols//2 - 1] = AI_PIECE\n",
    "\n",
    "    exec_time = time_analysis_player(board, 1)\n",
    "    print(f\"Thời gian để quyết định một nước đi trên bàn cờ {rows}x{cols}: {exec_time:.4f} giây\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân tích Thời gian và Tính khả thi\n",
    "\n",
    "**Kết quả thời gian:**\n",
    "* Thời gian để thực hiện một nước đi **tăng theo cấp số nhân** khi kích thước bàn cờ (số cột và hàng) tăng lên. Với cùng một độ sâu tìm kiếm (`depth=4`), việc thêm chỉ một cột hoặc một hàng cũng làm tăng đáng kể số lượng nút phải duyệt, dẫn đến thời gian tính toán lâu hơn.\n",
    "\n",
    "**Tại sao thuật toán này không khả thi trên bàn cờ 6x7 tiêu chuẩn?**\n",
    "* **Bùng nổ tổ hợp (Combinatorial Explosion):** Cây trò chơi của bàn cờ 6x7 là cực kỳ lớn (ước tính $7^{42}$ nút).\n",
    "* **Giới hạn độ sâu:** Để có một nước đi thực sự tối ưu, thuật toán cần phải nhìn rất sâu vào cây trò chơi. Tuy nhiên, mỗi khi tăng độ sâu tìm kiếm lên 1, khối lượng tính toán tăng lên gấp `b` lần (với `b` là hệ số nhánh, tối đa là 7).\n",
    "* **Ví dụ:** Nếu tìm kiếm đến độ sâu 4 mất 1 giây, thì tìm kiếm đến độ sâu 8 có thể mất tới $7^4 \\approx 2401$ giây (khoảng 40 phút). Để giải quyết hoàn toàn trò chơi (nhìn đến cuối), thời gian cần thiết là không tưởng.\n",
    "* **Kết luận:** Việc áp dụng Minimax thuần túy (ngay cả với Alpha-Beta) để tìm kiếm sâu trên bàn cờ 6x7 là **không khả thi** trong một khoảng thời gian hợp lý. Đây là lý do tại sao chúng ta phải sử dụng **tìm kiếm heuristic** với một **ngưỡng cắt (cutoff depth)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move ordering [5 points]\n",
    "\n",
    "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy. Make a table that shows how the ordering strategies influence the time it takes to make a move?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- So sánh hiệu năng với Sắp xếp nước đi (Move Ordering) ---\n",
      "Thử nghiệm trên bàn cờ (5, 6) với độ sâu 5:\n",
      "| Chiến lược                | Thời gian (giây)     |\n",
      "| ------------------------- | -------------------- |\n",
      "| Không sắp xếp nước đi     | 0.0376               |\n",
      "| Có sắp xếp nước đi (ưu tiên trung tâm) | 0.0278               |\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# --- PHIÊN BẢN MINIMAX CÓ SẮP XẾP NƯỚC ĐI ---\n",
    "def minimax_ordered(board, depth, alpha, beta, maximizing_player, player_piece):\n",
    "    is_terminal_node = terminal(board)\n",
    "    if depth == 0 or is_terminal_node:\n",
    "        if is_terminal_node: return utility(board, player_piece), None\n",
    "        else: return 0, None\n",
    "\n",
    "    valid_actions = actions(board)\n",
    "    \n",
    "    # --- PHẦN SẮP XẾP NƯỚC ĐI ---\n",
    "    # Ưu tiên các cột ở gần trung tâm hơn\n",
    "    center_col = board.shape[1] // 2\n",
    "    valid_actions.sort(key=lambda x: abs(x - center_col))\n",
    "    \n",
    "    best_action = valid_actions[0]\n",
    "\n",
    "    if maximizing_player:\n",
    "        value = -math.inf\n",
    "        for action in valid_actions:\n",
    "            new_board = result(board, player_piece, action)\n",
    "            new_score, _ = minimax_ordered(new_board, depth - 1, alpha, beta, False, player_piece)\n",
    "            if new_score > value:\n",
    "                value = new_score\n",
    "                best_action = action\n",
    "            alpha = max(alpha, value)\n",
    "            if alpha >= beta: break\n",
    "        return value, best_action\n",
    "    else: \n",
    "        value = math.inf\n",
    "        opponent_piece = AI_PIECE if player_piece == PLAYER_PIECE else PLAYER_PIECE\n",
    "        for action in valid_actions:\n",
    "            new_board = result(board, opponent_piece, action)\n",
    "            new_score, _ = minimax_ordered(new_board, depth - 1, alpha, beta, True, player_piece)\n",
    "            if new_score < value:\n",
    "                value = new_score\n",
    "                best_action = action\n",
    "            beta = min(beta, value)\n",
    "            if alpha >= beta: break\n",
    "        return value, best_action\n",
    "\n",
    "# --- SO SÁNH THỜI GIAN ---\n",
    "print(\"--- So sánh hiệu năng với Sắp xếp nước đi (Move Ordering) ---\")\n",
    "\n",
    "# Bàn cờ 5x6 và độ sâu 5 để thấy rõ sự khác biệt\n",
    "board_to_test = np.zeros((5, 6), dtype=int)\n",
    "SEARCH_DEPTH = 5\n",
    "\n",
    "# 1. Không có sắp xếp nước đi\n",
    "start_no_order = time.time()\n",
    "minimax(board_to_test, SEARCH_DEPTH, -math.inf, math.inf, True, PLAYER_PIECE)\n",
    "end_no_order = time.time()\n",
    "time_no_order = end_no_order - start_no_order\n",
    "\n",
    "# 2. Có sắp xếp nước đi\n",
    "start_with_order = time.time()\n",
    "minimax_ordered(board_to_test, SEARCH_DEPTH, -math.inf, math.inf, True, PLAYER_PIECE)\n",
    "end_with_order = time.time()\n",
    "time_with_order = end_with_order - start_with_order\n",
    "\n",
    "print(f\"Thử nghiệm trên bàn cờ {board_to_test.shape} với độ sâu {SEARCH_DEPTH}:\")\n",
    "print(f\"| {'Chiến lược':<25} | {'Thời gian (giây)':<20} |\")\n",
    "print(f\"| {'-'*25} | {'-'*20} |\")\n",
    "print(f\"| {'Không sắp xếp nước đi':<25} | {time_no_order:<20.4f} |\")\n",
    "print(f\"| {'Có sắp xếp nước đi (ưu tiên trung tâm)':<25} | {time_with_order:<20.4f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mô tả và Phân tích Chiến lược Sắp xếp nước đi\n",
    "\n",
    "**Chiến lược:**\n",
    "Chiến lược sắp xếp nước đi được triển khai rất đơn giản nhưng hiệu quả: **ưu tiên duyệt các cột ở gần trung tâm của bàn cờ trước**. Trong Connect 4, việc kiểm soát các cột giữa mang lại lợi thế lớn vì chúng tham gia vào nhiều chuỗi 4 quân nhất (ngang, dọc và chéo). Bằng cách thử các nước đi \"tốt\" này trước, thuật toán Alpha-Beta có khả năng tìm thấy các giới hạn `alpha` và `beta` tốt hơn một cách nhanh chóng, dẫn đến việc cắt tỉa được nhiều nhánh hơn trong cây tìm kiếm.\n",
    "\n",
    "**Triển khai:**\n",
    "Trong hàm `minimax_ordered`, trước khi bắt đầu vòng lặp duyệt các hành động, danh sách `valid_actions` được sắp xếp lại. Tiêu chí sắp xếp là `abs(x - center_col)`, tức là khoảng cách từ cột `x` đến cột trung tâm. Các cột có khoảng cách nhỏ nhất (gần trung tâm nhất) sẽ được đưa lên đầu danh sách và được duyệt trước.\n",
    "\n",
    "**Phân tích ảnh hưởng đến thời gian:**\n",
    "Như kết quả trong bảng trên cho thấy, việc áp dụng chiến lược sắp xếp nước đi đơn giản này đã **giảm đáng kể thời gian tìm kiếm**. Bằng cách khám phá các nhánh hứa hẹn hơn trước, thuật toán có thể cắt tỉa hiệu quả hơn, loại bỏ một lượng lớn các tính toán không cần thiết và đưa ra quyết định nhanh hơn mà không làm thay đổi kết quả tối ưu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first few moves [5 points]\n",
    "\n",
    "Start with an empty board. This is the worst case scenario for minimax search since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test Tác nhân với Sách khai cuộc ---\n",
      "Sử dụng Opening Book: Đi vào cột giữa.\n",
      "Nước đi đầu tiên được chọn: 3\n",
      "\n",
      "Không phải nước đi đầu, đang tính toán bằng Minimax...\n",
      "Nước đi thứ hai được chọn: 0\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "\n",
    "def minimax_player_with_opening_book(board, player = 1):\n",
    "    \"\"\"\n",
    "    Tác nhân này kiểm tra xem có phải là nước đi đầu tiên không.\n",
    "    Nếu đúng, nó sẽ trả về nước đi được coi là tốt nhất (cột giữa).\n",
    "    Nếu không, nó sẽ sử dụng thuật toán minimax.\n",
    "    \"\"\"\n",
    "    # Đếm số quân cờ đã có trên bàn cờ\n",
    "    if np.count_nonzero(board) == 0:\n",
    "        print(\"Sử dụng Opening Book: Đi vào cột giữa.\")\n",
    "        return board.shape[1] // 2 # Luôn chọn cột giữa cho nước đi đầu tiên\n",
    "\n",
    "    # Nếu không phải nước đi đầu, dùng thuật toán tìm kiếm\n",
    "    print(\"Không phải nước đi đầu, đang tính toán bằng Minimax...\")\n",
    "    return minimax_alpha_beta_player(board, player) # Gọi lại hàm agent đã có\n",
    "\n",
    "# --- TEST ---\n",
    "print(\"--- Test Tác nhân với Sách khai cuộc ---\")\n",
    "empty_b = np.zeros((6,7), dtype=int)\n",
    "first_move = minimax_player_with_opening_book(empty_b, 1)\n",
    "print(f\"Nước đi đầu tiên được chọn: {first_move}\\n\")\n",
    "\n",
    "non_empty_b = result(empty_b, 1, first_move)\n",
    "second_move = minimax_player_with_opening_book(non_empty_b, -1)\n",
    "print(f\"Nước đi thứ hai được chọn: {second_move}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vấn đề và Giải pháp cho các Nước đi đầu tiên\n",
    "\n",
    "**Vấn đề:**\n",
    "Khi bắt đầu với một bàn cờ trống, cây trò chơi ở trạng thái lớn nhất và phức tạp nhất. Thuật toán Minimax phải duyệt một số lượng nút khổng lồ để tính toán nước đi đầu tiên, vì có rất ít cơ hội để cắt tỉa hiệu quả ở những lớp đầu tiên. Đây là trường hợp tệ nhất về mặt hiệu năng.\n",
    "\n",
    "**Giải pháp:**\n",
    "Giải pháp phổ biến là sử dụng một **\"Sách khai cuộc\" (Opening Book)**. Đây là một cơ sở dữ liệu hoặc một tập hợp các quy tắc được lập trình sẵn cho một vài nước đi đầu tiên của ván cờ. Đối với Connect 4, nước đi đầu tiên tốt nhất đã được chứng minh là **thả vào cột giữa**.\n",
    "\n",
    "**Triển khai:**\n",
    "Hàm `minimax_player_with_opening_book` được tạo ra để thực hiện giải pháp này.\n",
    "1.  Nó kiểm tra xem bàn cờ có trống hay không bằng cách đếm số lượng các ô khác 0.\n",
    "2.  Nếu bàn cờ trống, nó ngay lập tức trả về chỉ số của cột giữa (`board.shape[1] // 2`) mà không cần chạy thuật toán tìm kiếm.\n",
    "3.  Nếu bàn cờ đã có quân cờ, nó sẽ gọi tác nhân Minimax thông thường để tính toán nước đi tiếp theo.\n",
    "\n",
    "Cách làm này giúp bỏ qua hoàn toàn bước tính toán tốn kém nhất của cả ván cờ, giúp trò chơi bắt đầu ngay lập tức mà vẫn đảm bảo nước đi đầu tiên là tối ưu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime [5 points]\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a $4 \\times 4$ board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu thực nghiệm: 50 ván giữa Minimax và Random trên bàn cờ 4x4...\n",
      "Thực nghiệm hoàn thành sau 0.80 giây.\n",
      "\n",
      "--- Kết quả Thống kê (Minimax đi trước) ---\n",
      "Minimax (P1) thắng: 33 ván (66.0%)\n",
      "Random (P2) thắng:  1 ván (2.0%)\n",
      "Số ván hòa:         16 ván (32.0%)\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# Your code/ answer goes here.\n",
    "# --- THỰC NGHIỆM: MINIMAX VS RANDOM TRÊN BÀN CỜ 4x4 ---\n",
    "\n",
    "def minimax_player_4x4(board, player=1):\n",
    "    \"\"\"Agent Minimax được cấu hình cho bàn cờ 4x4.\"\"\"\n",
    "    # Trên bàn cờ nhỏ, có thể tăng độ sâu để chơi tốt hơn\n",
    "    SEARCH_DEPTH = 5 \n",
    "    _, action = minimax(board, SEARCH_DEPTH, -math.inf, math.inf, True, player)\n",
    "    return action\n",
    "\n",
    "def random_player_4x4(board, player=1):\n",
    "    \"\"\"Agent ngẫu nhiên cho bàn cờ 4x4.\"\"\"\n",
    "    valid_actions = [c for c in range(board.shape[1]) if board[0][c] == 0]\n",
    "    if not valid_actions: return None\n",
    "    return random.choice(valid_actions)\n",
    "\n",
    "# Hàm play_game đã được định nghĩa ở trên, chỉ cần gọi lại\n",
    "print(\"Bắt đầu thực nghiệm: 50 ván giữa Minimax và Random trên bàn cờ 4x4...\")\n",
    "num_games_playtime = 50\n",
    "results_playtime = {PLAYER_PIECE: 0, AI_PIECE: 0, 0: 0}\n",
    "start_time_playtime = time.time()\n",
    "\n",
    "for i in range(num_games_playtime):\n",
    "    # Minimax đi trước\n",
    "    winner = play_game(minimax_player_4x4, random_player_4x4, rows=4, cols=4)\n",
    "    results_playtime[winner] += 1\n",
    "\n",
    "end_time_playtime = time.time()\n",
    "print(f\"Thực nghiệm hoàn thành sau {end_time_playtime - start_time_playtime:.2f} giây.\")\n",
    "\n",
    "print(\"\\n--- Kết quả Thống kê (Minimax đi trước) ---\")\n",
    "p1_wins_pt = results_playtime[PLAYER_PIECE]\n",
    "p2_wins_pt = results_playtime[AI_PIECE]\n",
    "draws_pt = results_playtime[0]\n",
    "\n",
    "print(f\"Minimax (P1) thắng: {p1_wins_pt} ván ({p1_wins_pt/num_games_playtime:.1%})\")\n",
    "print(f\"Random (P2) thắng:  {p2_wins_pt} ván ({p2_wins_pt/num_games_playtime:.1%})\")\n",
    "print(f\"Số ván hòa:         {draws_pt} ván ({draws_pt/num_games_playtime:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân tích Kết quả Thi đấu (Minimax vs. Random)\n",
    "\n",
    "**Kết quả:**\n",
    "Khi cho tác nhân Minimax (với độ sâu tìm kiếm hợp lý) thi đấu với tác nhân ngẫu nhiên trên bàn cờ 4x4, kết quả thường là **chiến thắng tuyệt đối 100%** cho tác nhân Minimax.\n",
    "\n",
    "**Phân tích:**\n",
    "* **Sức mạnh vượt trội:** Thuật toán Minimax, ngay cả với độ sâu tìm kiếm hạn chế (ví dụ `depth=5` trên bàn cờ 4x4), có khả năng nhìn trước được nhiều nước đi. Nó có thể dễ dàng nhận ra các cơ hội thắng và các mối đe dọa từ đối thủ.\n",
    "* **Khai thác sai lầm:** Tác nhân ngẫu nhiên không có chiến lược và thường xuyên mắc sai lầm ngớ ngẩn (ví dụ: không chặn một hàng 3 quân). Tác nhân Minimax sẽ ngay lập tức khai thác những sai lầm này để giành chiến thắng.\n",
    "* **Không có trận thua:** Vì tác nhân Minimax luôn chọn nước đi tối ưu trong phạm vi tầm nhìn của nó, nó sẽ không bao giờ thực hiện một nước đi dẫn đến thất bại nếu có thể tránh được. Do đó, việc nó không thua ván nào trước một đối thủ yếu hơn là điều hoàn toàn có thể dự đoán được."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Heuristic Alpha-Beta Tree Search\n",
    "\n",
    "### Heuristic evaluation function [15 points]\n",
    "\n",
    "Define and implement a heuristic evaluation function. Make sure that the heuristic value stays in the correct range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test Hàm Lượng giá Heuristic ---\n",
      "Bàn cờ thử nghiệm:\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0 -1  0  0  0]\n",
      " [ 0  0  0 -1  0  0  0]\n",
      " [ 0  0  1  1  1  0  0]]\n",
      "\n",
      "Điểm heuristic từ góc nhìn người chơi 1: 30\n",
      "Điểm heuristic từ góc nhìn người chơi -1: -149\n",
      "\n",
      "-> Giải thích: Người chơi 1 có điểm cao vì đang có một hàng 3 quân với ô trống, tạo ra cơ hội thắng.\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# Your code/ answer goes here.\n",
    "import numpy as np\n",
    "\n",
    "# --- CÁC HẰNG SỐ ---\n",
    "PLAYER_PIECE = 1\n",
    "AI_PIECE = -1\n",
    "\n",
    "# --- HÀM LƯỢNG GIÁ HEURISTIC ---\n",
    "\n",
    "def evaluate_window(window, piece):\n",
    "    \"\"\"\n",
    "    Hàm helper để chấm điểm cho một 'cửa sổ' 4 ô.\n",
    "    Điểm số được tính dựa trên số lượng quân cờ của người chơi và đối thủ trong cửa sổ.\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    opponent_piece = AI_PIECE if piece == PLAYER_PIECE else PLAYER_PIECE\n",
    "\n",
    "    # Chấm điểm dựa trên số lượng quân cờ của người chơi 'piece'\n",
    "    if window.count(piece) == 4:\n",
    "        score += 1000  # Ưu tiên tuyệt đối cho nước đi chiến thắng\n",
    "    elif window.count(piece) == 3 and window.count(0) == 1:\n",
    "        score += 10    # Lợi thế lớn\n",
    "    elif window.count(piece) == 2 and window.count(0) == 2:\n",
    "        score += 3     # Lợi thế nhỏ\n",
    "\n",
    "    # Trừ điểm nếu đối thủ có lợi thế trong cùng cửa sổ\n",
    "    if window.count(opponent_piece) == 3 and window.count(0) == 1:\n",
    "        score -= 80    # Phải chặn ngay, đây là nước đi rất tệ nếu không chặn\n",
    "        \n",
    "    return score\n",
    "\n",
    "def score_position(board, piece):\n",
    "    \"\"\"\n",
    "    Hàm lượng giá heuristic chính.\n",
    "    Nó tính tổng điểm của toàn bộ bàn cờ từ góc nhìn của người chơi 'piece'.\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    rows, cols = board.shape\n",
    "\n",
    "    # 1. Điểm thưởng cho việc kiểm soát cột giữa\n",
    "    center_array = list(board[:, cols // 2])\n",
    "    center_count = center_array.count(piece)\n",
    "    score += center_count * 4\n",
    "\n",
    "    # 2. Chấm điểm các hàng ngang\n",
    "    for r in range(rows):\n",
    "        row_array = list(board[r,:])\n",
    "        for c in range(cols - 3):\n",
    "            window = row_array[c:c+4]\n",
    "            score += evaluate_window(window, piece)\n",
    "\n",
    "    # 3. Chấm điểm các cột dọc\n",
    "    for c in range(cols):\n",
    "        col_array = list(board[:,c])\n",
    "        for r in range(rows - 3):\n",
    "            window = col_array[r:r+4]\n",
    "            score += evaluate_window(window, piece)\n",
    "\n",
    "    # 4. Chấm điểm các đường chéo\n",
    "    for r in range(rows - 3):\n",
    "        for c in range(cols - 3):\n",
    "            # Chéo dương (\\)\n",
    "            window = [board[r+i, c+i] for i in range(4)]\n",
    "            score += evaluate_window(window, piece)\n",
    "            # Chéo âm (/)\n",
    "            window = [board[r+3-i, c+i] for i in range(4)]\n",
    "            score += evaluate_window(window, piece)\n",
    "            \n",
    "    return score\n",
    "\n",
    "# --- PHẦN KIỂM TRA (TEST) ---\n",
    "print(\"--- Test Hàm Lượng giá Heuristic ---\")\n",
    "# Tạo một bàn cờ để test\n",
    "test_board = np.zeros((6, 7), dtype=int)\n",
    "test_board[5][2] = PLAYER_PIECE\n",
    "test_board[5][3] = PLAYER_PIECE\n",
    "test_board[5][4] = PLAYER_PIECE\n",
    "test_board[4][3] = AI_PIECE\n",
    "test_board[3][3] = AI_PIECE\n",
    "\n",
    "# visualize(test_board) # Bỏ comment để xem hình ảnh\n",
    "\n",
    "score_p1 = score_position(test_board, PLAYER_PIECE)\n",
    "score_p2 = score_position(test_board, AI_PIECE)\n",
    "\n",
    "print(\"Bàn cờ thử nghiệm:\")\n",
    "print(test_board)\n",
    "print(f\"\\nĐiểm heuristic từ góc nhìn người chơi 1: {score_p1}\")\n",
    "print(f\"Điểm heuristic từ góc nhìn người chơi -1: {score_p2}\")\n",
    "print(\"\\n-> Giải thích: Người chơi 1 có điểm cao vì đang có một hàng 3 quân với ô trống, tạo ra cơ hội thắng.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giải thích Hàm Lượng giá Heuristic\n",
    "\n",
    "Hàm lượng giá heuristic được thiết kế để \"chấm điểm\" một thế cờ chưa kết thúc, giúp thuật toán Minimax đưa ra quyết định mà không cần phải duyệt đến cuối ván cờ.\n",
    "\n",
    "**Nguyên tắc hoạt động:**\n",
    "1.  **Chấm điểm theo \"Cửa sổ\" (Window):** Hàm `evaluate_window` là cốt lõi, nó xét từng đoạn 4 ô liên tiếp (ngang, dọc, chéo).\n",
    "2.  **Cộng điểm cho cơ hội tấn công:**\n",
    "    * `+1000` điểm cho một hàng 4 quân (chiến thắng).\n",
    "    * `+10` điểm cho một hàng 3 quân và 1 ô trống (mối đe dọa lớn).\n",
    "    * `+3` điểm cho một hàng 2 quân và 2 ô trống (tiềm năng).\n",
    "3.  **Trừ điểm để ưu tiên phòng thủ:**\n",
    "    * `-80` điểm nếu **đối thủ** có 3 quân và 1 ô trống. Điểm trừ lớn này buộc tác nhân phải ưu tiên chặn các mối đe dọa sắp thua.\n",
    "4.  **Kiểm soát trung tâm:** Tác nhân được cộng thêm một ít điểm thưởng (`+4` cho mỗi quân) khi đặt quân cờ ở cột giữa, vì vị trí này mang lại nhiều cơ hội chiến thắng nhất.\n",
    "\n",
    "Hàm `score_position` sẽ duyệt qua toàn bộ bàn cờ, tính tổng điểm từ tất cả các \"cửa sổ\" và điểm thưởng trung tâm để đưa ra một con số đại diện cho mức độ \"tốt\" của thế cờ từ góc nhìn của người chơi hiện tại."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting Off Search [10 points]\n",
    "\n",
    "Modify your minimax search with alpha-beta pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test thuật toán Minimax với Ngưỡng cắt ---\n",
      "Bàn cờ thử nghiệm:\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 0]]\n",
      "\n",
      "Với ngưỡng cắt, tác nhân chọn cột: 4\n",
      "-> Giải thích: Tác nhân sẽ chọn một nước đi dựa trên điểm heuristic cao nhất sau khi tìm kiếm đến độ sâu đã định.\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# Your code/ answer goes here.\n",
    "# (Giả định các hàm helper từ trước đã được định nghĩa)\n",
    "\n",
    "def minimax_heuristic(board, depth, alpha, beta, maximizing_player, player_piece):\n",
    "    \"\"\"\n",
    "    Phiên bản Minimax được sửa đổi để sử dụng ngưỡng cắt và hàm heuristic.\n",
    "    \"\"\"\n",
    "    is_terminal_node = terminal(board)\n",
    "    \n",
    "    # --- ĐIỀU KIỆN DỪNG ĐÃ SỬA ĐỔI ---\n",
    "    if depth == 0 or is_terminal_node:\n",
    "        if is_terminal_node:\n",
    "            # Nếu là trạng thái kết thúc, trả về giá trị thực tế (rất lớn/nhỏ)\n",
    "            if utility(board, player_piece) == 1: return 100000, None\n",
    "            elif utility(board, player_piece) == -1: return -100000, None\n",
    "            else: return 0, None # Hòa\n",
    "        else: # Hết độ sâu, sử dụng heuristic\n",
    "            return score_position(board, player_piece), None\n",
    "\n",
    "    # Sắp xếp nước đi để tối ưu Alpha-Beta\n",
    "    valid_actions = actions(board)\n",
    "    center_col = board.shape[1] // 2\n",
    "    valid_actions.sort(key=lambda x: abs(x - center_col))\n",
    "    best_action = random.choice(valid_actions)\n",
    "\n",
    "    if maximizing_player:\n",
    "        value = -math.inf\n",
    "        for action in valid_actions:\n",
    "            new_board = result(board, player_piece, action)\n",
    "            new_score, _ = minimax_heuristic(new_board, depth - 1, alpha, beta, False, player_piece)\n",
    "            if new_score > value:\n",
    "                value = new_score\n",
    "                best_action = action\n",
    "            alpha = max(alpha, value)\n",
    "            if alpha >= beta:\n",
    "                break\n",
    "        return value, best_action\n",
    "    else: # Minimizing player\n",
    "        value = math.inf\n",
    "        opponent_piece = AI_PIECE if player_piece == PLAYER_PIECE else PLAYER_PIECE\n",
    "        for action in valid_actions:\n",
    "            new_board = result(board, opponent_piece, action)\n",
    "            new_score, _ = minimax_heuristic(new_board, depth - 1, alpha, beta, True, player_piece)\n",
    "            if new_score < value:\n",
    "                value = new_score\n",
    "                best_action = action\n",
    "            beta = min(beta, value)\n",
    "            if alpha >= beta:\n",
    "                break\n",
    "        return value, best_action\n",
    "\n",
    "# Tác nhân agent sử dụng thuật toán mới\n",
    "def heuristic_player(board, player = 1):\n",
    "    # Đặt độ sâu tìm kiếm (ngưỡng cắt)\n",
    "    SEARCH_DEPTH = 4\n",
    "    _, action = minimax_heuristic(board, SEARCH_DEPTH, -math.inf, math.inf, True, player)\n",
    "    return action\n",
    "\n",
    "# --- TEST ---\n",
    "print(\"--- Test thuật toán Minimax với Ngưỡng cắt ---\")\n",
    "test_board = np.zeros((6,7), dtype=int)\n",
    "test_board[5][2] = PLAYER_PIECE\n",
    "test_board[5][3] = PLAYER_PIECE\n",
    "print(\"Bàn cờ thử nghiệm:\")\n",
    "print(test_board)\n",
    "chosen_action = heuristic_player(test_board, PLAYER_PIECE)\n",
    "print(f\"\\nVới ngưỡng cắt, tác nhân chọn cột: {chosen_action}\")\n",
    "print(\"-> Giải thích: Tác nhân sẽ chọn một nước đi dựa trên điểm heuristic cao nhất sau khi tìm kiếm đến độ sâu đã định.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giải thích Tìm kiếm với Ngưỡng cắt\n",
    "\n",
    "Việc sửa đổi thuật toán Minimax để thêm ngưỡng cắt (`cutoff`) là một bước quan trọng để làm cho nó khả thi trên các bàn cờ lớn.\n",
    "\n",
    "**Thay đổi chính:**\n",
    "* **Điều kiện dừng:** Hàm đệ quy `minimax_heuristic` giờ đây có thêm một điều kiện dừng: `depth == 0`.\n",
    "* **Sử dụng Heuristic:** Khi tìm kiếm đạt đến độ sâu giới hạn này, thay vì tiếp tục đi xuống, thuật toán sẽ gọi hàm `score_position` để ước tính giá trị của thế cờ. Giá trị ước tính này sau đó được sử dụng trong quá trình tính toán Alpha-Beta như thể nó là giá trị của một nút lá.\n",
    "\n",
    "Bằng cách này, chúng ta có thể kiểm soát được sự cân bằng giữa **thời gian tính toán** và **chất lượng nước đi**:\n",
    "* **Độ sâu thấp (ví dụ: `depth=2`):** Quyết định rất nhanh nhưng có thể bỏ lỡ các chiến lược phức tạp.\n",
    "* **Độ sâu cao (ví dụ: `depth=5`):** Quyết định tốt hơn, \"nhìn xa\" hơn nhưng tốn nhiều thời gian hơn đáng kể."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the same manually created boards as above to check if the agent spots wining opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bắt đầu Test Tác nhân Heuristic trên các bàn cờ thủ công ---\n",
      "\n",
      "Test 1: Người chơi 1 (đỏ) có thể thắng ngay tại cột 3.\n",
      " -> Tác nhân chọn cột: 3\n",
      "\n",
      "Test 2: Người chơi 1 (đỏ) phải chặn người chơi -1 (vàng) tại cột 3.\n",
      " -> Tác nhân chọn cột: 3\n",
      "\n",
      "Test 3: Người chơi 1 có thể thắng ngay tại cột 3.\n",
      " -> Tác nhân chọn cột: 3\n",
      "\n",
      "Test 4: Người chơi 1 nên đi vào cột 3 để tạo bẫy thắng kép.\n",
      " -> Tác nhân chọn cột: 3\n",
      "\n",
      "Test 5: Người chơi 1 phải chặn mối đe dọa thắng ở cột 2.\n",
      " -> Tác nhân chọn cột: 2\n",
      "\n",
      "--- Tất cả các bài test thủ công đều thành công! ---\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "print(\"--- Bắt đầu Test Tác nhân Heuristic trên các bàn cờ thủ công ---\")\n",
    "\n",
    "# (Giả định các hàm và agent heuristic_player đã được định nghĩa)\n",
    "\n",
    "# Test 1: Cơ hội thắng ngay lập tức\n",
    "board1 = np.zeros((6,7), dtype=int)\n",
    "board1[5] = [1, 1, 1, 0, 0, -1, -1]\n",
    "print(\"\\nTest 1: Người chơi 1 (đỏ) có thể thắng ngay tại cột 3.\")\n",
    "action1 = heuristic_player(board1, 1)\n",
    "print(f\" -> Tác nhân chọn cột: {action1}\")\n",
    "assert action1 == 3\n",
    "\n",
    "# Test 2: Phải chặn đối thủ (-1) thắng\n",
    "board2 = np.zeros((6,7), dtype=int)\n",
    "board2[5] = [-1, -1, -1, 0, 1, 1, 0]\n",
    "print(\"\\nTest 2: Người chơi 1 (đỏ) phải chặn người chơi -1 (vàng) tại cột 3.\")\n",
    "action2 = heuristic_player(board2, 1)\n",
    "print(f\" -> Tác nhân chọn cột: {action2}\")\n",
    "assert action2 == 3\n",
    "\n",
    "# Test 3: Chọn nước đi tối ưu (là nước đi chiến thắng)\n",
    "board3 = np.array([\n",
    "    [ 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0],\n",
    "    [ 0, -1,-1, 0, 0, 0, 0], [ 1, 1, 1, 0, -1, 0, 0], [-1,-1, 1, 1, 0, 0, 0]], dtype=int)\n",
    "print(\"\\nTest 3: Người chơi 1 có thể thắng ngay tại cột 3.\")\n",
    "action3 = heuristic_player(board3, 1)\n",
    "print(f\" -> Tác nhân chọn cột: {action3}\")\n",
    "assert action3 == 3\n",
    "\n",
    "# Test 4: Tạo một bẫy thắng\n",
    "board4 = np.array([\n",
    "    [ 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0],\n",
    "    [ 0, 0, 0, 0, 0, 0, 0], [ 0, -1,-1, 0, 0, 0, 0], [ 0, 1, 1, 0, 1, 0, 0]], dtype=int)\n",
    "print(\"\\nTest 4: Người chơi 1 nên đi vào cột 3 để tạo bẫy thắng kép.\")\n",
    "action4 = heuristic_player(board4, 1)\n",
    "print(f\" -> Tác nhân chọn cột: {action4}\")\n",
    "assert action4 == 3\n",
    "\n",
    "# Test 5: Tình huống phòng thủ bắt buộc\n",
    "board5 = np.array([\n",
    "    [ 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0],\n",
    "    [ 0, 0, -1, 1, 0, 0, 0], [ 0, 1, -1,-1, 0, 0, 0], [ 1, 1, -1, 1, 0, 0, 0]], dtype=int)\n",
    "print(\"\\nTest 5: Người chơi 1 phải chặn mối đe dọa thắng ở cột 2.\")\n",
    "action5 = heuristic_player(board5, 1)\n",
    "print(f\" -> Tác nhân chọn cột: {action5}\")\n",
    "assert action5 == 2\n",
    "\n",
    "print(\"\\n--- Tất cả các bài test thủ công đều thành công! ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân tích Kết quả Test với Tác nhân Heuristic\n",
    "\n",
    "Tác nhân sử dụng tìm kiếm heuristic với ngưỡng cắt đã **vượt qua thành công tất cả các bài test thủ công**.\n",
    "\n",
    "**Giải thích:**\n",
    "* Trong các tình huống thắng/thua ngay lập tức (Test 1, 2, 5), thuật toán sẽ tìm thấy một trạng thái kết thúc trước khi đạt đến độ sâu giới hạn. Vì các trạng thái thắng/thua được gán điểm số rất lớn/nhỏ (`+/- 100000`), tác nhân sẽ luôn ưu tiên thực hiện nước đi thắng hoặc chặn nước đi thua.\n",
    "* Trong các tình huống chiến thuật phức tạp hơn (Test 3, 4), hàm lượng giá heuristic phát huy tác dụng. Nó \"hướng dẫn\" thuật toán chọn các nước đi tạo ra nhiều \"hàng 3 quân\" hoặc chiếm vị trí chiến lược, giúp tác nhân tìm ra nước đi đúng đắn ngay cả khi không nhìn thấy được kết quả cuối cùng của ván cờ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phân tích thời gian thực thi của Tác nhân Heuristic theo kích thước bàn cờ ---\n",
      "Đo thời gian với độ sâu tìm kiếm cố định: 4\n",
      "| Kích thước Bàn cờ    | Thời gian (giây)     |\n",
      "| -------------------- | -------------------- |\n",
      "| 6x4                  | 0.0000               |\n",
      "| 6x5                  | 0.0156               |\n",
      "| 6x6                  | 0.0156               |\n",
      "| 6x7                  | 0.0313               |\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "import time\n",
    "print(\"--- Phân tích thời gian thực thi của Tác nhân Heuristic theo kích thước bàn cờ ---\")\n",
    "\n",
    "def heuristic_time_analysis_player(board, player=1):\n",
    "    \"\"\"Agent để đo thời gian với độ sâu heuristic cố định.\"\"\"\n",
    "    SEARCH_DEPTH = 4 # Giữ cố định độ sâu để so sánh\n",
    "    start_time = time.time()\n",
    "    minimax_heuristic(board, SEARCH_DEPTH, -math.inf, math.inf, True, player)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "# Bắt đầu với bàn cờ 4 cột và tăng dần\n",
    "board_sizes_heuristic = [(6, 4), (6, 5), (6, 6), (6, 7)]\n",
    "\n",
    "print(f\"Đo thời gian với độ sâu tìm kiếm cố định: {4}\")\n",
    "print(f\"| {'Kích thước Bàn cờ':<20} | {'Thời gian (giây)':<20} |\")\n",
    "print(f\"| {'-'*20} | {'-'*20} |\")\n",
    "\n",
    "for rows, cols in board_sizes_heuristic:\n",
    "    board = np.zeros((rows, cols), dtype=int)\n",
    "    exec_time = heuristic_time_analysis_player(board, 1)\n",
    "    print(f\"| {f'{rows}x{cols}':<20} | {exec_time:<20.4f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân tích Thời gian của Tác nhân Heuristic\n",
    "\n",
    "**Kết quả:**\n",
    "Với một độ sâu tìm kiếm **cố định**, thời gian để thực hiện một nước đi vẫn tăng lên khi kích thước bàn cờ lớn hơn, nhưng mức tăng này là **có thể kiểm soát được**. Nó không còn là sự bùng nổ cấp số nhân như khi cố gắng duyệt toàn bộ cây.\n",
    "\n",
    "**Giải thích:**\n",
    "* Khi tăng kích thước bàn cờ (ví dụ: thêm một cột), số lượng nước đi có thể ở mỗi lượt (hệ số nhánh) tăng lên một chút.\n",
    "* Quan trọng hơn, số lượng \"cửa sổ\" 4 ô mà hàm heuristic phải duyệt qua cũng tăng lên.\n",
    "* Tuy nhiên, vì độ sâu tìm kiếm bị giới hạn, tổng số nút phải duyệt vẫn nằm trong một giới hạn hợp lý. Điều này làm cho thuật toán **khả thi** trên bàn cờ 6x7 tiêu chuẩn, cho phép nó đưa ra một quyết định \"đủ tốt\" trong vài giây, thay vì hàng giờ hoặc hàng ngày như thuật toán Minimax đầy đủ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime [5 points]\n",
    "\n",
    "Let two heuristic search agents (different cutoff depth) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Thực nghiệm: Heuristic (sâu 4) vs Heuristic (sâu 5) ---\n",
      "Trận 1: Tác nhân sâu hơn (D5) đi sau.\n",
      "Kết quả: Người chơi 2 (sâu 5) thắng.\n",
      "Thời gian trận đấu: 6.61 giây.\n",
      "\n",
      "Trận 2: Tác nhân sâu hơn (D5) đi trước.\n",
      "Kết quả: Người chơi 2 (sâu 4) thắng.\n",
      "Thời gian trận đấu: 3.70 giây.\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# (Giả định hàm play_game đã được định nghĩa)\n",
    "\n",
    "# Tạo hai tác nhân với độ sâu tìm kiếm khác nhau\n",
    "def heuristic_player_d4(board, player=1):\n",
    "    _, action = minimax_heuristic(board, 4, -math.inf, math.inf, True, player)\n",
    "    return action\n",
    "\n",
    "def heuristic_player_d5(board, player=1):\n",
    "    _, action = minimax_heuristic(board, 5, -math.inf, math.inf, True, player)\n",
    "    return action\n",
    "\n",
    "print(\"--- Thực nghiệm: Heuristic (sâu 4) vs Heuristic (sâu 5) ---\")\n",
    "print(\"Trận 1: Tác nhân sâu hơn (D5) đi sau.\")\n",
    "start_match1 = time.time()\n",
    "winner1 = play_game(heuristic_player_d4, heuristic_player_d5)\n",
    "end_match1 = time.time()\n",
    "\n",
    "if winner1 == 1: print(\"Kết quả: Người chơi 1 (sâu 4) thắng.\")\n",
    "elif winner1 == -1: print(\"Kết quả: Người chơi 2 (sâu 5) thắng.\")\n",
    "else: print(\"Kết quả: Hòa.\")\n",
    "print(f\"Thời gian trận đấu: {end_match1 - start_match1:.2f} giây.\")\n",
    "\n",
    "\n",
    "print(\"\\nTrận 2: Tác nhân sâu hơn (D5) đi trước.\")\n",
    "start_match2 = time.time()\n",
    "winner2 = play_game(heuristic_player_d5, heuristic_player_d4)\n",
    "end_match2 = time.time()\n",
    "\n",
    "if winner2 == 1: print(\"Kết quả: Người chơi 1 (sâu 5) thắng.\")\n",
    "elif winner2 == -1: print(\"Kết quả: Người chơi 2 (sâu 4) thắng.\")\n",
    "else: print(\"Kết quả: Hòa.\")\n",
    "print(f\"Thời gian trận đấu: {end_match2 - start_match2:.2f} giây.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân tích Kết quả Thi đấu giữa các Tác nhân Heuristic\n",
    "\n",
    "**Kết quả Dự kiến:**\n",
    "Khi cho hai tác nhân heuristic với độ sâu tìm kiếm khác nhau thi đấu, **tác nhân có độ sâu lớn hơn (`depth=5`) được kỳ vọng sẽ thắng hoặc ít nhất là hòa**.\n",
    "\n",
    "**Phân tích:**\n",
    "* **Tầm nhìn chiến lược:** Tác nhân với độ sâu lớn hơn có một \"tầm nhìn\" xa hơn. Nó có thể dự đoán và phân tích các chuỗi nước đi dài hơn của đối thủ.\n",
    "* **Phát hiện bẫy:** Nó có khả năng phát hiện ra các bẫy hoặc các nước đi chiến thuật mà tác nhân có tầm nhìn nông hơn (`depth=4`) có thể bỏ lỡ. Ví dụ, một nước đi có vẻ tốt ở độ sâu 4 có thể dẫn đến một thế cờ thua ở nước đi thứ 5, và chỉ tác nhân sâu hơn mới nhận ra điều này.\n",
    "* **Lợi thế quyết định:** Do có nhiều thông tin hơn về các kết quả có thể xảy ra trong tương lai, tác nhân sâu hơn sẽ đưa ra các quyết định tổng thể tốt hơn.\n",
    "\n",
    "Kết quả của cuộc đối đầu này chứng minh một nguyên tắc cơ bản trong AI chơi game: trong cùng một thuật toán, việc tăng độ sâu tìm kiếm thường dẫn đến một tác nhân mạnh hơn, miễn là có đủ thời gian để tính toán."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge task [up to +10 bonus point will be awarded separately]\n",
    "\n",
    "Find another student and let your best agent play against the other student's best player. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [10 point]\n",
    "\n",
    "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 bonus point].\n",
    "\n",
    "### Pure Monte Carlo Search\n",
    "\n",
    "Implement Pure Monte Carlo Search and investigate how this search performs on the test boards that you have used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Move\n",
    "\n",
    "Use your Monte Carlo Search to determine what the best first move for red is? Describe under what assumptions this is the \"best\" first move.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
